{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from sklearn.neighbors import KDTree\n",
    "from scipy.spatial import distance \n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import copy\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-16573f54b045>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import words\n",
    "from nltk.corpus import wordnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(wordnet.words())\n",
    "\n",
    "def is_word(word):\n",
    "    # NOTE: Removing hyphenated words too.\n",
    "    return (\n",
    "        not any(c in word for c in '-_. \\'\"0123456789,<>!@#$%^&*({[]})')\n",
    "    )\n",
    "print(len(words))\n",
    "\n",
    "words = [w for w in words if is_word(w)]\n",
    "print(len(words))\n",
    "# Also convert everything to lower case... Maybe I don't want place names though..??\n",
    "words = { w.lower() for w in words }\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_by_length = defaultdict(list)\n",
    "\n",
    "for w in words:\n",
    "    words_by_length[len(w)].append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Memoize\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def words_from_constraint(length, position, letter):\n",
    "    return { w for w in words_by_length[length] if w[position] == letter }\n",
    "\n",
    "def words_from_constraints(length, constraints):\n",
    "    if not constraints:\n",
    "        return words_by_length[length]\n",
    "    \n",
    "    sets = [words_from_constraint(length, position, letter)\n",
    "            for position, letter in constraints]\n",
    "    \n",
    "    return set.intersection(*sets)\n",
    "\n",
    "\n",
    "words_from_constraints(5, [(0, 'a'), (3, 'b')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A word is just a list of positions that're covered by that word in the grid.\n",
    "# Could store 'position', 'direction' but...\n",
    "\n",
    "# Generate all words in a grid\n",
    "\n",
    "size_x = 5  # Width\n",
    "size_y = 5\n",
    "\n",
    "# | 0,0 | 1,0 | ..\n",
    "# | 0,1 | 1,1 | ..\n",
    "#   ..    ..\n",
    "\n",
    "words = []\n",
    "\n",
    "for i in range(size_x):\n",
    "    words.append(\n",
    "        [(i, j) for j in range(size_y)]\n",
    "    )\n",
    "    \n",
    "for j in range(size_y):\n",
    "    words.append(\n",
    "        [(i, j) for i in range(size_x)]\n",
    "    )\n",
    "    \n",
    "random.shuffle(words)\n",
    "\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nice_print(grid):\n",
    "    print('+-' * len(grid[0]) + '+')\n",
    "    for row in grid:\n",
    "        print('|' + '|'.join(row) + '|')\n",
    "        print('+-' * len(row) + '+')\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid = [[' ' for i in range(size_x)] for j in range(size_y)]\n",
    "# NOTE: Accessed with grid[y][x]\n",
    "\n",
    "node_tracker = defaultdict(int)\n",
    "\n",
    "def dfs(depth):\n",
    "    node_tracker[depth] += 1\n",
    "    \n",
    "    if depth >= len(words):\n",
    "        yield copy.deepcopy(grid)\n",
    "        return\n",
    "        \n",
    "    # Build constraints for this word.\n",
    "    new_letters = []\n",
    "    constraints = []\n",
    "    for ix, (i,j) in enumerate(words[depth]):\n",
    "        c = grid[j][i]\n",
    "        if c == ' ':\n",
    "            new_letters.append((ix, i, j))\n",
    "        else:\n",
    "            constraints.append((ix, c))\n",
    "\n",
    "#     print(new_letters, constraints, ix)\n",
    "\n",
    "    # Find words.\n",
    "    possible_words = words_from_constraints(ix+1, constraints)\n",
    "    #print('found:', len(possible_words), 'possible words')\n",
    "    #print(ix+1, constraints)\n",
    "    for w in possible_words:\n",
    "        # Insert word into grid...\n",
    "        for ix, i, j in new_letters:\n",
    "            grid[j][i] = w[ix]\n",
    "            \n",
    "        # Recurse\n",
    "        for ans in dfs(depth + 1):\n",
    "            yield ans\n",
    "        \n",
    "        # Remove word from grid\n",
    "        for ix, i, j in new_letters:\n",
    "            grid[j][i] = ' '\n",
    "      \n",
    "x = dfs(0)\n",
    "for i in range(100):\n",
    "    nice_print(next(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_tracker  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +-+-+-+-+-+\n",
    "# |h|a|r|s|h|\n",
    "# +-+-+-+-+-+\n",
    "# |a|m|a|t|i|\n",
    "# +-+-+-+-+-+\n",
    "# |l|i|d|a|r|\n",
    "# +-+-+-+-+-+\n",
    "# |a|g|i|l|e|\n",
    "# +-+-+-+-+-+\n",
    "# |b|o|x|e|r|\n",
    "# +-+-+-+-+-+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
