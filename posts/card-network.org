#+BEGIN_COMMENT
.. title: Card Network
.. slug: card-network
.. date: 2020-05-24 23:36:12 UTC+01:00
.. tags: programming, machine-learning
.. category: i-made
.. link:
.. has_math: true
.. description: A tiny neural network in c++
.. type: text
#+END_COMMENT

#+PROPERTY: header-args :exports code

* Business Card Neural Network
I recently came across Andrew Kensler's fascinating [[https://fabiensanglard.net/rayTracing_back_of_business_card/][Business Card Raytracer]]. His code, in just 1337 bytes, generates a full raytraced image complete with depth of field, reflections, a sky gradient, and a textured floor. In a similar vein, I set out to create a full neural network that could fit on the back of a business card. The code below is the result, creating a 3-layer fully-connected neural network with leaky-relu activations and training it to generate a small image of my name.

#+BEGIN_EXPORT html
<div style="text-align:center">
<div style="display:inline-block; text-align:left">
#+END_EXPORT
#+BEGIN_SRC cpp
#include <bits/stdc++.h>

typedef float f;typedef std::vector<f> v;
f K=0.01,R=0.01;struct L{int w,h,i;v W,x,
z;L(int i,int o){W.resize(i*o);for(f&a:W)
a=(rand()/(1.1-(1<<31))-0.5)/sqrt(i+o+0.)
;w=i;h=o;}v F(v X){x=X;v a(h);i=h*w;while
(i--)a[i/w]+=W[i]*x[i%w];z=a;for(f&i:a)i=
K>i?K:i;return a;}v B(v Y){v X(w);i=w*h;
while(i--){f Z=Y[i/w]*(z[i/w]>0?1:K);X[i%
w]+=Z*W[i];W[i]-=R*Z*x[i%w];}return X;}};
int main(){L n[]{L(40,50),L(50,50),L(50,1
)};int l,z,k,i=500337;while(i--){z=242-i%
243;k=40;v x(k),y;while(k--)x[k]=sin((k%2
?z/27/3.:z%27/5.)+6.14*k/20);y=x;for(l=0;
l<3;l++)y=n[l].F(y);v Y{2*(y[0]-("\x1e\0\
\0\b\x01\0@H\374\377B\x12@\x18\x12G\302\
\x10@\x12\372\377\221\x10\0\0\200\0\0\0\
\x02"[z/8]>>z%8&1))};while(l--)Y=n[l].B(Y
);putchar(" .,-*oO##"[(int)(y[0]*8)%9]);
if(i%27<1)puts(i?i%243?"":"\033[9A":"\r\
   --- Oisin Carroll ---\n\
 gh:Oisincar  web:imois.in");}}
#+END_SRC
#+BEGIN_EXPORT html
</div>
</div>
#+END_EXPORT

You can view the output here by clicking the play button. (I hate to admit it's not actually running the code in the browser :P, but you'll see the same or similar output if you run the code yourself).

#+BEGIN_EXPORT html
<div style="text-align:right; position:relative;">
<div class="terminal-code" id="div1" style="height:13em; padding:0.5em" >> ./card_network</div>
<button class="button-pp" style="position:absolute; top:15px; right:5px;"></button>
<script src="../assets/js/card_network/fk_network.js"></script>
</div>
#+END_EXPORT

The code is only 878 characters, and (as mentioned previously) creates and trains a small neural network. I'm sure it's possible to make it shorter still, but I was happy enough to get this far! I think making it any shorter would make it impossible to reason about, now at least new layers can be added or removed easily and the forward/back propagation is pretty neat! (I'm not biased I swear).

Here's a small breakdown of how it works.

#+BEGIN_EXPORT css
code-col {
    display:inline-block;
    text-align:left
}
#+END_EXPORT

# Open big column, wrap code block.
# <div style="text-align:center; column-count:2">
#+BEGIN_EXPORT html
<div class="code-row">
<div class="code-col">
#+END_EXPORT
#+BEGIN_SRC cpp
#include <bits/stdc++.h>

typedef float f;typedef std::vector<f> v;
f K=0.01,R=0.01;
#+END_SRC
#+BEGIN_EXPORT html
</div>
<div class="code-col">
#+END_EXPORT

Define simple imports and typedefs. The two floats define constants used for the 'leak' of leaky relu, (I.e. the $K$ in $f(x) = max(Kx, x)$), and the learning rate.

# Close column divs... Start again!

#+BEGIN_EXPORT html
</div>
</div>
<div class="code-row">
<div class="code-col">
#+END_EXPORT
#+BEGIN_SRC cpp
                struct L{int w,h,i;v W,x,
z;L(int i,int o){W.resize(i*o);for(f&a:W)
a=(rand()/(1.1-(1<<31))-0.5)/sqrt(i+o+0.)
;w=i;h=o;}
#+END_SRC
#+BEGIN_EXPORT html
</div>
<div class="code-col">
#+END_EXPORT

Start of the layer struct src_cpp{L}. The constructor takes the input and output sizes, and initializes a weights matrix in an approximation of [[https://towardsdatascience.com/weight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79][Xavier Initilization]]. Ideally, the random variable would be normally distributed, but linearly seems to work decently too!

#+BEGIN_EXPORT html
</div>
</div>
<div class="code-row">
<div class="code-col">
#+END_EXPORT
#+BEGIN_SRC cpp
          v F(v X){x=X;v a(h);i=h*w;while
(i--)a[i/w]+=W[i]x[i%w];z=a;for(f&i:a)i=
K>i?K:i;return a;}v B(v Y){v X(w);i=w*h;
while(i--){f Z=Y[i/w]*(z[i/w]>0?1:K);X[i%
w]+=Z*W[i];W[i]-=R*Z*x[i%w];}return X;}};
#+END_SRC
#+BEGIN_EXPORT html
</div>
<div class="code-col">
#+END_EXPORT

Two functions for the layer struct. src_cpp{F} performs forward propagation, taking the input vector and returning the output. Some values are cached for later. src_cpp{B} performs backward propagation, taking the derivative of the output, updating the weights matrix, and returning the derivative of the input. Both are using leaky relu.

#+BEGIN_EXPORT html
</div>
</div>
<div class="code-row">
<div class="code-col">
#+END_EXPORT
#+BEGIN_SRC cpp
int main(){L n[]{L(40,50),L(50,50),L(50,1
)};int l,z,k,i=500337;while(i--){
#+END_SRC
#+BEGIN_EXPORT html
</div>
<div class="code-col">
#+END_EXPORT
Start of main, create a 3 layer network. The network takes 40 values for input, and has two hidden layers with 50 nodes each, and returns single value at the end. The input is based on the x,y coordinate currently predicted, and the output is a single value for whether this pixel should be a space or '#'. At the end we open the training loop, which runs for 500336 iterations, which is a multiple of the output size; 243.
#+BEGIN_EXPORT html
</div>
</div>
<div class="code-row">
<div class="code-col">
#+END_EXPORT
#+BEGIN_SRC cpp
                                 z=242-i%
243;k=40;v x(k),y;while(k--)x[k]=sin((k%2
?z/27/3.:z%27/5.)+6.14*k/20);
#+END_SRC
#+BEGIN_EXPORT html
</div>
<div class="code-col">
#+END_EXPORT
Generate the input vector src_cpp{x}. Each element of src_cpp{x} is based on the sin of either the x or y coordinate of the pixel currently being predicted.
#+BEGIN_EXPORT html
</div>
</div>
<div class="code-row">
<div class="code-col">
#+END_EXPORT
#+BEGIN_SRC cpp
                             y=x;for(l=0;
l<3;l++)y=n[l].F(y);
#+END_SRC
#+BEGIN_EXPORT html
</div>
<div class="code-col smol-text-col">
#+END_EXPORT
Forward propagation
#+BEGIN_EXPORT html
</div>
</div>
<div class="code-row">
<div class="code-col">
#+END_EXPORT
#+BEGIN_SRC cpp
                    v Y{2*(y[0]-("\x1e\0\
\0\b\x01\0@H\374\377B\x12@\x18\x12G\302\
\x10@\x12\372\377\221\x10\0\0\200\0\0\0\
\x02"[z/8]>>z%8&1))};
#+END_SRC
#+BEGIN_EXPORT html
</div>
<div class="code-col smol-text-col">
#+END_EXPORT
From the output of the network, src_cpp{y}, calculate $\frac{dE}{dy}$. We use mean squared error, so the derivative is just $2(y-\hat{y})$, where $\hat{y}$ is the target value and is encoded in a string. When written with non-ascii characters this is a lot shorter.
#+BEGIN_EXPORT html
</div>
</div>
<div class="code-row">
<div class="code-col">
#+END_EXPORT
#+BEGIN_SRC cpp
                     while(l--)Y=n[l].B(Y
);
#+END_SRC
#+BEGIN_EXPORT html
</div>
<div class="code-col smol-text-col">
#+END_EXPORT
Back propagation
#+BEGIN_EXPORT html
</div>
</div>
<div class="code-row">
<div class="code-col">
#+END_EXPORT
#+BEGIN_SRC cpp
  putchar(" .,-*oO##"[(int)(y[0]*8)%9]);
if(i%27<1)puts(i?i%243?"":"\033[9A":"\r\
   --- Oisin Carroll ---\n\
 gh:Oisincar  web:imois.in");}}
#+END_SRC
#+BEGIN_EXPORT html
</div>
<div class="code-col">
#+END_EXPORT
Output: Choose different chars based on how high/low the value predicted is. Then print special characters if we're at the end of a line (src_cpp{i%27==0}) or we've done a full epoch (src_cpp{i%243==0}). Finally, when we're finished, src_cpp{i==0} and we print the end text.
#+BEGIN_EXPORT html
</div>
</div>
#+END_EXPORT


* Optimizations:
On reddit =/u/pm_me_P_vs_NP_papers= managed to shorten the code even further - by 50 bytes! They used some fantastically clever byte packing, improved loops and more. Their final length is only 828 bytes and 22 lines. You can read about their optimizations [[https://www.reddit.com/r/tinycode/comments/hiscpb/business_card_neural_network/fwkg9i9?utm_source=share&utm_medium=web2x][HERE!]]

UPDATE (OCT/2022). I decided to replicate their updates here, in case their post gets deleted in the future.

** =/u/pm_me_P_vs_NP_papers=' reddit post:
Awesome demo! I managed to get it from 878 bytes 23 lines down to 828 bytes 22 lines:

#+BEGIN_SRC cpp
#include <bits/stdc++.h>

using f=float;using v=std::vector<f>;f K,
R=K=.01,Z;struct L{int w,h,i;v W,x,z;L(int
i,int o){W.resize(i*o);for(f&a:W)a=(rand(
)/(1.1-(1<<31))-.5)/sqrt(i+o+0.);w=i;h=o;
}v F(v X){x=X;v a(h);for(i=h*w;i--;)a[i/w
]+=W[i]*x[i%w];z=a;for(f&i:a)i=K>i?K:i;
return a;}v B(v Y){v X(w);for(i=h*w;i
--;X[i%w]+=Z*W[i],W[i]-=R*Z*x[i%w])Z=Y[i/
w]*(z[i/w]>0?1:K);return X;}};int main(){
L n[]{L(40,50),L(50,50),L(50,1)};int T[]=
{30,66,67093636,16795915,38212120,9438256
,18874273,66,128,128},i=500337,z,k;while(
i--){z=242-i%243;k=40;v x(k),y;while(k--)
x[k]=sin((k%2?z/27/3.:z%27/5.)+.307*k);y=
x;for(L&l:n)y=l.F(y);v Y{2*(y[0]-(T[z/26]
>>z%26&1))};for(z=3;z--;)Y=n[z].B(Y);
putchar(" .,-*oO##"[(int)(y[0]*8)%9]);if(
i%27<1)puts(i?i%243?"":"\033[9A":"\r\
   --- Oisin Carroll ---\n\
 gh:Oisincar  web:imois.in");}}
 #+END_SRC

By far the biggest shave was compressing the "training data" string. My first idea was to store an array of 16 bit integers instead of a string of inefficiently encoded 8 bit values, but then I figured there might be some other even more efficient number of bits per value, and with this python script:

#+BEGIN_SRC python
data = b"\x1e\0\0\b\x01\0@H\374\377B\x12@\x18\x12G\302\x10@\x12\372\377\221\x10\0\0\200\0\0\0\x02" + b"\0"*32

data_bits = ""
for c in data:
	data_bits += bin(c+256)[-8:][::-1] # reverse each byte so we can reverse again later (gah endianness)

for bits_per in range(1, 32):
	v = []
	for i in range(0, len(data_bits), bits_per):
		v.append(int(data_bits[i:i+bits_per][::-1], 2))
	while v[-1] == 0: v = v[:-1] # shave trailing zeros
	s = "{"
	for x in v:
		if len(str(x)) < len(hex(x)):
			s += str(x) + ","
		else:
			s += hex(x) + ","
	s = s[:-1] + "}"
	print(bits_per, s)
#+END_SRC

I found the most efficient encoding was 26 bits / element, with this array: {30,66,67093636,16795915,38212120,9438256,18874273,66,128,128} which I called T in main. The lookup was also slightly adjusted to T[z/26]>>z%26&1.

Some other less dramatic shaves are:

Shorter type aliases:

#+BEGIN_SRC c++
typedef float f;typedef std::vector<f> v;
using f=float;using v=std::vector<f>;
#+END_SRC

Shorter float declarations (including changing some 0.5 to .5, etc.):

#+BEGIN_SRC c++
f K=0.01,R=0.01;
f K,R=K=.01;
#+END_SRC

Shorter loops:

#+BEGIN_SRC c++
i=h*w;while(i--)
for(i=h*w;i--;)
#+END_SRC

Shorter loops v2:

#+BEGIN_SRC c++
for(l=0;l<3;l++)y=n[l].F(y); [snip] while(l--)Y=n[l].B(Y);
for(l=0;l<3;)y=n[l++].F(y); [snip] while(l--)Y=n[l].B(Y);
for(L&l:n)y=l.F(y); [snip] for(l=3;l--;)Y=n[l].B(Y);
//                             ^ reuse z here instead of l -> one less declaration
#+END_SRC

Shorter constants:

#+BEGIN_SRC c++
6.14*k/20
.307*k
#+END_SRC

Shorter loops v3: (get rid of brackets by bunching expression statements in the increment field)

The only downside is that Z must be declared outside the for loop, and you can either play it safe by declaring it right before the loop, or play it slightly risky and declare Z globally (because there was already a global float declaration which we can take advantage of)

#+BEGIN_SRC c++
for(i=h*w;i--;){f Z=Y[i/w]*(z[i/w]>0?1:K);X[i%w]+=Z*W[i];W[i]-=R*Z*x[i%w];}
f Z;for(i=h*w;i--;X[i%w]+=Z*W[i],W[i]-=R*Z*x[i%w])Z=Y[i/w]*(z[i/w]>0?1:K);
#+END_SRC
-> declare Z globally since there are never going to be two instances of this
function ever running recursively (-4+2 chars)


* End...

Thanks for reading! I'd love to hear suggestions on how to make it shorter, or any other ideas.
